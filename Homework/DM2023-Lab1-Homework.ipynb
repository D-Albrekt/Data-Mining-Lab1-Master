{"cells":[{"cell_type":"markdown","metadata":{"id":"FDNTc1wFid-1"},"source":["### Student Information\n","Name: David Albrekt\n","\n","Student ID: x1120011\n","\n","GitHub ID: D-Albrekt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Answer here\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Answer here\n"]},{"cell_type":"markdown","metadata":{},"source":["### >>> **Exercise 5 (take home)** \n","There is an old saying that goes, \"The devil is in the details.\" When we are working with extremely large data, it's difficult to check records one by one (as we have been doing so far). And also, we don't even know what kind of missing values we are facing. Thus, \"debugging\" skills get sharper as we spend more time solving bugs. Let's focus on a different method to check for missing values and the kinds of missing values you may encounter. It's not easy to check for missing values as you will find out in a minute.\n","\n","Please check the data and the process below, describe what you observe and why it happened.   \n","$Hint$ :  why `.isnull()` didn't work?"]},{"cell_type":"markdown","metadata":{"id":"-BajKEF_id-5"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"rSzgpPbVid-6"},"source":["### Instructions"]},{"cell_type":"markdown","metadata":{"id":"UjbdfsDcid-6"},"source":["1. First: do the **take home** exercises in the [DM2023-Lab1-Master](https://github.com/fjrialdnc0615/DM2023-Lab1-Master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n","\n","\n","2. Second: follow the same process from the [DM2023-Lab1-Master](https://github.com/fjrialdnc0615/DM2023-Lab1-Master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n","    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. You need to combine three labeled datasets into one file for your data preparation part.\n","    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n","\n","\n","3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n","    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n","    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n","    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n","\n","\n","4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be habdled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n","\n","\n","5. Fifth: It's hard for us to follow if your code is messy, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n","\n","\n","You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fjrialdnc0615/DM2023-Lab1-Master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (October 27th 11:59 pm, Thursday)__. "]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1666241724343,"user":{"displayName":"Kevin Yang","userId":"04518680380941289042"},"user_tz":-480},"id":"IDH6foBIid-9"},"outputs":[],"source":["### Init blockt to create the panda DF X\n","from sklearn.datasets import fetch_20newsgroups\n","import pandas as pd\n","# my functions\n","import sys\n","sys.path.append('../')\n","import helpers.data_mining_helpers as dmh\n","# categories\n","categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n","# obtain the documents containing the categories provided\n","twenty_train = fetch_20newsgroups(subset='train', categories=categories,\n","                                  shuffle=True, random_state=42)\n","# construct dataframe from a list\n","X = pd.DataFrame.from_records(dmh.format_rows(twenty_train), columns= ['text'])\n","# add category to the dataframe\n","X['category'] = twenty_train.target\n","# add category label also\n","X['category_name'] = X.category.apply(lambda t: dmh.format_labels(t, twenty_train))"]},{"cell_type":"markdown","metadata":{},"source":["### ** >>> Exercise 2 (take home):** \n","Experiment with other querying techniques using pandas dataframes. Refer to their [documentation](https://pandas.pydata.org/pandas-docs/stable/indexing.html) for more information. "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>category</th>\n","      <th>category_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>From: djohnson@cs.ucsd.edu (Darin Johnson) Sub...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","    <tr>\n","      <th>309</th>\n","      <td>From: caralv@caralv.auto-trol.com (Carol Alvin...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","    <tr>\n","      <th>608</th>\n","      <td>From: hudson@athena.cs.uga.edu (Paul Hudson Jr...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","    <tr>\n","      <th>955</th>\n","      <td>From: MNHCC@cunyvm.bitnet (Marty Helgesen) Sub...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","    <tr>\n","      <th>1289</th>\n","      <td>Subject: Fluids vs Liquids From: mikec@sail.LA...</td>\n","      <td>0</td>\n","      <td>alt.atheism</td>\n","    </tr>\n","    <tr>\n","      <th>1603</th>\n","      <td>From: JEK@cu.nih.gov Subject: When are two peo...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","    <tr>\n","      <th>1897</th>\n","      <td>From: shellgate!llo@uu4.psi.com (Larry L. Over...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","    <tr>\n","      <th>2190</th>\n","      <td>From: REXLEX@fnal.fnal.gov Subject: Re: Athies...</td>\n","      <td>3</td>\n","      <td>soc.religion.christian</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   text  category  \\\n","2     From: djohnson@cs.ucsd.edu (Darin Johnson) Sub...         3   \n","309   From: caralv@caralv.auto-trol.com (Carol Alvin...         3   \n","608   From: hudson@athena.cs.uga.edu (Paul Hudson Jr...         3   \n","955   From: MNHCC@cunyvm.bitnet (Marty Helgesen) Sub...         3   \n","1289  Subject: Fluids vs Liquids From: mikec@sail.LA...         0   \n","1603  From: JEK@cu.nih.gov Subject: When are two peo...         3   \n","1897  From: shellgate!llo@uu4.psi.com (Larry L. Over...         3   \n","2190  From: REXLEX@fnal.fnal.gov Subject: Re: Athies...         3   \n","\n","               category_name  \n","2     soc.religion.christian  \n","309   soc.religion.christian  \n","608   soc.religion.christian  \n","955   soc.religion.christian  \n","1289             alt.atheism  \n","1603  soc.religion.christian  \n","1897  soc.religion.christian  \n","2190  soc.religion.christian  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["X[(X['category'] > 2) | (X['category'] < 1)][::150]\n","#In this example it is pretty weird to use\n","# this kind of notation, but if category instead would have been\n","# Likes or similair, then you maybe wants to see text with more than\n","# 50 likes for example. \n","# We also se multiple conditions in use here."]},{"cell_type":"markdown","metadata":{},"source":["### >>> **Exercise 5 (take home)** \n","There is an old saying that goes, \"The devil is in the details.\" When we are working with extremely large data, it's difficult to check records one by one (as we have been doing so far). And also, we don't even know what kind of missing values we are facing. Thus, \"debugging\" skills get sharper as we spend more time solving bugs. Let's focus on a different method to check for missing values and the kinds of missing values you may encounter. It's not easy to check for missing values as you will find out in a minute.\n","\n","Please check the data and the process below, describe what you observe and why it happened.   \n","$Hint$ :  why `.isnull()` didn't work?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>missing_example</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>D</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>E</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>F</td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id missing_example\n","0  A             NaN\n","1  B             NaN\n","2  C             NaN\n","3  D            None\n","4  E            None\n","5  F                "]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","\n","NA_dict = [{ 'id': 'A', 'missing_example': np.nan },\n","           { 'id': 'B'                    },\n","           { 'id': 'C', 'missing_example': 'NaN'  },\n","           { 'id': 'D', 'missing_example': 'None' },\n","           { 'id': 'E', 'missing_example':  None  },\n","           { 'id': 'F', 'missing_example': ''     }]\n","\n","NA_df = pd.DataFrame(NA_dict, columns = ['id','missing_example'])\n","NA_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["0     True\n","1     True\n","2    False\n","3    False\n","4     True\n","5    False\n","Name: missing_example, dtype: bool"]},"metadata":{},"output_type":"display_data"}],"source":["NA_df['missing_example'].isnull()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Answer here\n","#The df.isnull() funciton can only detect missing values in the form of\n","# the python datatype None, np.nan, and also when the value is \n","# missing(Since it then becomes None). This is why 0,1,4 becomes true,\n","# however, for 2,3,5 there is a saved string in which makes the is.null()\n","# function belive that there are a stored value and therefore labels it as false. "]},{"cell_type":"markdown","metadata":{},"source":["### >>> Exercise 6 (take home):\n","Notice any changes from the `X` dataframe to the `X_sample` dataframe? What are they? Report every change you noticed as compared to the previous state of `X`. Feel free to query and look more closely at the dataframe for these changes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Answer here\n","'''\n","There are two main changes that occcours from the sampling (x --> x_sample) and that is\n"," 1. The amount of records (length) get reduced to 1000 compared to the previous 2257\n"," 2. The order of the records is randomized, hence it is not the first 1 - 1000 records who are selected\n","    instead it is randomized like record 561 first then record 241 and so on until the total amount of records is 1000.\n","'''\n"]}],"metadata":{"colab":{"collapsed_sections":["PQPCUbx1ie4R","8qg4up1B_EhD","lC7ymUlG_fai","xtvWLH1x_7nV","bgULadKFBXL-","SZ4rgA1mBir5","9VirxMl6CGN2","yoTS9Vh8ESzB","NGVM3wSjFt7v","bH9BQLSWF9Uf","y8I6L8Z8JGsv","TFIl1hpMJqnv","DobYRQ4FLetu","9pfemrkcLiUG"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}

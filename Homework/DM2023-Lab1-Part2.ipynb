{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this Notebook, the second part of Lab1 in the DataMining course is performed to improve maintainability and readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Data Source\n",
    "2. Data Preparation \n",
    "3. Data Transformation\n",
    "-  Converting Dictionary into Pandas dataframe\n",
    "4. Data Mining using Pandas\n",
    " - 4.1 Dealing with Missing Values\n",
    " - 4.2 Dealing with Duplicate Data\n",
    "5. Data Preprocessing\n",
    " - 5.1 Sampling\n",
    " - 5.2 Feature Creation\n",
    " - 5.3 Feature Subset Selection\n",
    " - 5.4 Dimensionality Reduction\n",
    " - 5.5 Atrribute Transformation / Aggregation\n",
    " - 5.6 Discretization and Binarization\n",
    "6. Data Exploration\n",
    "7. Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Data\n",
    "In this notebook we will explore Sentiment Labelled sentences, The used dataset could be found [here](https://archive.ics.uci.edu/dataset/331/sentiment+labelled+sentences). The dataset contains sentences labelled with positive or negative sentiment. Additional information about the dataset, provided by the author of the website above, is provided below:\n",
    "\n",
    "     This dataset was created for the Paper 'From Group to Individual Labels using Deep Features', Kotzias et. al,. KDD 2015\n",
    "     Please cite the paper if you want to use it :\n",
    "\n",
    "     It contains sentences labelled with positive or negative sentiment.\n",
    "\n",
    "     # Format:\n",
    "\n",
    "     sentence \t score \n",
    "\n",
    "     # Details:\n",
    "\n",
    "     Score is either 1 (for positive) or 0 (for negative)\t\n",
    "     The sentences come from three different websites/fields:\n",
    "\n",
    "     imdb.com\n",
    "     amazon.com\n",
    "     yelp.com\n",
    "\n",
    "     For each website, there exist 500 positive and 500 negative sentences. Those were selected randomly for larger datasets  of reviews. \n",
    "     We attempted to select sentences that have a clearly positive or negative connotaton, the goal was for no neutral sentences to be selected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 3. Data Preparation & Data Transformation\n",
    "In this section we will extract the data from their files into one single panda dataframe.\n",
    "The dataframe will ultimatly have the format:\n",
    "\n",
    "INDEX   |   sentence    |    Score  |   Source    Positive/Negative   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import helpers.data_mining_helpers as dmh\n",
    "\n",
    "current_folder = os.getcwd()\n",
    "file_path = current_folder + \"\\sentiment+labelled+sentences\\sentimentlabelledsentences\\\\\" #Change file_path to fit where you put the txt_files\n",
    "\n",
    "category = {0 : 'Negative', 1 : 'Positive'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp DF shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "yelp_df = pd.read_csv(file_path + \"yelp_labelled.txt\", names=['sentence', 'Score'], sep='\\t')\n",
    "yelp_df['Source'] = 'Yelp'\n",
    "print(\"Yelp DF shape: \" + str(yelp_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon DF shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "amazon_df = pd.read_csv(os.path.join(file_path + \"amazon_cells_labelled.txt\"), names=['sentence', 'Score'], sep='\\t')\n",
    "amazon_df['Source'] = 'Amazon'\n",
    "print(\"Amazon DF shape: \" + str(amazon_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB DF shape: (748, 3)\n",
      "New IMDB DF shape: (1000, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imdb_df = pd.read_csv(os.path.join(file_path + \"imdb_labelled.txt\"), names=['sentence', 'Score'], sep='\\t')\n",
    "imdb_df['Source'] = 'IMDB'\n",
    "print(\"IMDB DF shape: \" + str(imdb_df.shape))\n",
    "#Since it seems to be something wrong during the import of the IMDB records (only 748 records...) \n",
    "# I will import those records using classic read from file operations and then  sperate the string & lines\n",
    "file = open(file_path + \"imdb_labelled.txt\")\n",
    "imdb_raw_data = file.read()\n",
    "file.close\n",
    "imdb_raw_data = imdb_raw_data.split('\\n')\n",
    "\n",
    "x = []\n",
    "sentence = []\n",
    "score = []\n",
    "for line in imdb_raw_data[0:1000]: #Use index 0:1000 to avoid the last empty line. \n",
    "    x = line.split('\\t')\n",
    "    sentence.append(x[0])\n",
    "    score.append(x[-1])\n",
    "imdb_df = pd.DataFrame({'sentence' : sentence, 'Score' : score})\n",
    "imdb_df['Source'] = 'IMDB'\n",
    "print(\"New IMDB DF shape: \" + str(imdb_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence Score  Source\n",
       "0    So there is no way for me to plug it in here i...     0  Amazon\n",
       "1                          Good case, Excellent value.     1  Amazon\n",
       "2                               Great for the jawbone.     1  Amazon\n",
       "3    Tied to charger for conversations lasting more...     0  Amazon\n",
       "4                                    The mic is great.     1  Amazon\n",
       "..                                                 ...   ...     ...\n",
       "995  I just got bored watching Jessice Lange take h...     0    IMDB\n",
       "996  Unfortunately, any virtue in this film's produ...     0    IMDB\n",
       "997                   In a word, it is embarrassing.       0    IMDB\n",
       "998                               Exceptionally bad!       0    IMDB\n",
       "999  All in all its an insult to one's intelligence...     0    IMDB\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.concat([amazon_df, yelp_df, imdb_df], axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Score  Source\n",
       "0  So there is no way for me to plug it in here i...     0  Amazon\n",
       "1                        Good case, Excellent value.     1  Amazon"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So there is no way for me to plug it in here in the US unless I go by a converter.\n",
      "Good case, Excellent value.\n",
      "Great for the jawbone.\n"
     ]
    }
   ],
   "source": [
    "for sentence in df['sentence'][:3]:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Positive/Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Score  Source  \\\n",
       "0  So there is no way for me to plug it in here i...     0  Amazon   \n",
       "1                        Good case, Excellent value.     1  Amazon   \n",
       "2                             Great for the jawbone.     1  Amazon   \n",
       "3  Tied to charger for conversations lasting more...     0  Amazon   \n",
       "4                                  The mic is great.     1  Amazon   \n",
       "5  I have to jiggle the plug to get it to line up...     0  Amazon   \n",
       "6  If you have several dozen or several hundred c...     0  Amazon   \n",
       "7        If you are Razr owner...you must have this!     1  Amazon   \n",
       "8                Needless to say, I wasted my money.     0  Amazon   \n",
       "9                   What a waste of money and time!.     0  Amazon   \n",
       "\n",
       "  Positive/Negative  \n",
       "0          Negative  \n",
       "1          Positive  \n",
       "2          Positive  \n",
       "3          Negative  \n",
       "4          Positive  \n",
       "5          Negative  \n",
       "6          Negative  \n",
       "7          Positive  \n",
       "8          Negative  \n",
       "9          Negative  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add Positive/Negative column to the DF\n",
    "df['Positive/Negative'] = df.Score.apply(lambda t: dmh.format_labels_lab2(t, category))\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Positive/Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence Positive/Negative\n",
       "0  So there is no way for me to plug it in here i...          Negative\n",
       "1                        Good case, Excellent value.          Positive\n",
       "2                             Great for the jawbone.          Positive\n",
       "3  Tied to charger for conversations lasting more...          Negative\n",
       "4                                  The mic is great.          Positive\n",
       "5  I have to jiggle the plug to get it to line up...          Negative\n",
       "6  If you have several dozen or several hundred c...          Negative\n",
       "7        If you are Razr owner...you must have this!          Positive\n",
       "8                Needless to say, I wasted my money.          Negative\n",
       "9                   What a waste of money and time!.          Negative"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple query\n",
    "df[:10][[\"sentence\",\"Positive/Negative\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Positive/Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>The opening sequence of this gem is a classic,...</td>\n",
       "      <td>1</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Fans of the genre will be in heaven.</td>\n",
       "      <td>1</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Lange had become a great actress.</td>\n",
       "      <td>1</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>It looked like a wonderful story.</td>\n",
       "      <td>1</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>I never walked out of a movie faster.</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence Score Source  \\\n",
       "990  The opening sequence of this gem is a classic,...     1   IMDB   \n",
       "991             Fans of the genre will be in heaven.       1   IMDB   \n",
       "992                Lange had become a great actress.       1   IMDB   \n",
       "993                It looked like a wonderful story.       1   IMDB   \n",
       "994            I never walked out of a movie faster.       0   IMDB   \n",
       "995  I just got bored watching Jessice Lange take h...     0   IMDB   \n",
       "996  Unfortunately, any virtue in this film's produ...     0   IMDB   \n",
       "997                   In a word, it is embarrassing.       0   IMDB   \n",
       "998                               Exceptionally bad!       0   IMDB   \n",
       "999  All in all its an insult to one's intelligence...     0   IMDB   \n",
       "\n",
       "    Positive/Negative  \n",
       "990          Positive  \n",
       "991          Positive  \n",
       "992          Positive  \n",
       "993          Positive  \n",
       "994          Negative  \n",
       "995          Negative  \n",
       "996          Negative  \n",
       "997          Negative  \n",
       "998          Negative  \n",
       "999          Negative  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Last 10\n",
    "df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Empty DataFrame\n",
      "Columns: [sentence, Score, Source, Positive/Negative, index]\n",
      "Index: []\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Cannot get right slice bound for non-unique label: 10'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\albre\\OneDrive - Linköpings universitet\\NTHUDataMining\\Data-Mining-Lab1-Master\\Homework\\DM2023-Lab1-Part2.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/albre/OneDrive%20-%20Link%C3%B6pings%20universitet/NTHUDataMining/Data-Mining-Lab1-Master/Homework/DM2023-Lab1-Part2.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m duplicates \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mduplicated()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/albre/OneDrive%20-%20Link%C3%B6pings%20universitet/NTHUDataMining/Data-Mining-Lab1-Master/Homework/DM2023-Lab1-Part2.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39msum\u001b[39m(df\u001b[39m.\u001b[39mduplicated()))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/albre/OneDrive%20-%20Link%C3%B6pings%20universitet/NTHUDataMining/Data-Mining-Lab1-Master/Homework/DM2023-Lab1-Part2.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df\u001b[39m.\u001b[39;49mloc[:\u001b[39m10\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msentence\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1150\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1329\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1330\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[0;32m   1332\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexing.py:1063\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             \u001b[39mreturn\u001b[39;00m section\n\u001b[0;32m   1062\u001b[0m         \u001b[39m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[1;32m-> 1063\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(section, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)[new_key]\n\u001b[0;32m   1065\u001b[0m \u001b[39mraise\u001b[39;00m IndexingError(\u001b[39m\"\u001b[39m\u001b[39mnot applicable\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1152\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexing.py:1373\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1372\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1373\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1374\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getbool_axis(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexing.py:1405\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1402\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1404\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1405\u001b[0m indexer \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39;49mslice_indexer(slice_obj\u001b[39m.\u001b[39;49mstart, slice_obj\u001b[39m.\u001b[39;49mstop, slice_obj\u001b[39m.\u001b[39;49mstep)\n\u001b[0;32m   1407\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(indexer, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   1408\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_slice(indexer, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6601\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6557\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_indexer\u001b[39m(\n\u001b[0;32m   6558\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   6559\u001b[0m     start: Hashable \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   6560\u001b[0m     end: Hashable \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   6561\u001b[0m     step: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   6562\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mslice\u001b[39m:\n\u001b[0;32m   6563\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   6564\u001b[0m \u001b[39m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6565\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6599\u001b[0m \u001b[39m    slice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6600\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6601\u001b[0m     start_slice, end_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mslice_locs(start, end, step\u001b[39m=\u001b[39;49mstep)\n\u001b[0;32m   6603\u001b[0m     \u001b[39m# return a slice\u001b[39;00m\n\u001b[0;32m   6604\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6824\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6822\u001b[0m end_slice \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   6823\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 6824\u001b[0m     end_slice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_slice_bound(end, \u001b[39m\"\u001b[39;49m\u001b[39mright\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   6825\u001b[0m \u001b[39mif\u001b[39;00m end_slice \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   6826\u001b[0m     end_slice \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\albre\\anaconda3\\envs\\DataMining\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6751\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6749\u001b[0m     slc \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_booleans_to_slice(slc\u001b[39m.\u001b[39mview(\u001b[39m\"\u001b[39m\u001b[39mu1\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   6750\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(slc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m-> 6751\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m   6752\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot get \u001b[39m\u001b[39m{\u001b[39;00mside\u001b[39m}\u001b[39;00m\u001b[39m slice bound for non-unique \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6753\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlabel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(original_label)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6754\u001b[0m         )\n\u001b[0;32m   6756\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(slc, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   6757\u001b[0m     \u001b[39mif\u001b[39;00m side \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Cannot get right slice bound for non-unique label: 10'"
     ]
    }
   ],
   "source": [
    "#using loc (by label)\n",
    "#df.loc[:10,\"sentence\"]\n",
    "duplicates = df.duplicated()\n",
    "print(sum(df.duplicated()))\n",
    "print(df[duplicates])\n",
    "'''\n",
    "Since there is rows that are considered \n",
    "duplicated rows the loc can't be used,\n",
    "but after further investigation it seems\n",
    "like they isn't really duplicates therefore\n",
    "a new extra index column is added... \n",
    "'''\n",
    "import numpy as np\n",
    "df['index'] = np.arange(3000)\n",
    "df[0:10]\n",
    "duplicates = df.duplicated()\n",
    "print(sum(df.duplicated()))\n",
    "df.loc[:10, 'sentence']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
